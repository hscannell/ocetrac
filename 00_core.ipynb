{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocetrac\n",
    "\n",
    "> Track and label marine heatwaves from geospatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nbdev.showdoc import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from skimage.measure import regionprops \n",
    "from skimage.measure import label as label_np\n",
    "import dask.array as dsa\n",
    "\n",
    "# import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _morphological_operations(da, radius=8): \n",
    "    '''Converts xarray.DataArray to binary, defines structuring element, and performs morphological closing then opening.\n",
    "    Parameters\n",
    "    ----------\n",
    "    da     : xarray.DataArray\n",
    "            The data to label\n",
    "    radius : int\n",
    "            Length of grid spacing to define the radius of the structing element used in morphological closing and opening.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Convert images to binary. All positive values == 1, otherwise == 0\n",
    "    bitmap_binary = da.where(da>0, drop=False, other=0)\n",
    "    bitmap_binary = bitmap_binary.where(bitmap_binary==0, drop=False, other=1)\n",
    "    \n",
    "    # Define structuring element\n",
    "    diameter = radius*2\n",
    "    x = np.arange(-radius, radius+1)\n",
    "    x, y = np.meshgrid(x, x)\n",
    "    r = x**2+y**2 \n",
    "    se = r<radius**2\n",
    "\n",
    "    def binary_open_close(bitmap_binary):\n",
    "        bitmap_binary_padded = np.pad(bitmap_binary,\n",
    "                                      ((diameter, diameter), (diameter, diameter)),\n",
    "                                      mode='wrap')\n",
    "        s1 = scipy.ndimage.binary_closing(bitmap_binary_padded, se, iterations=1)\n",
    "        s2 = scipy.ndimage.binary_opening(s1, se, iterations=1)\n",
    "        unpadded= s2[diameter:-diameter, diameter:-diameter]\n",
    "        return unpadded\n",
    "    \n",
    "    mo_binary = xr.apply_ufunc(binary_open_close, bitmap_binary,\n",
    "                               input_core_dims=[['lat', 'lon']],\n",
    "                               output_core_dims=[['lat', 'lon']],\n",
    "                               output_dtypes=[bitmap_binary.dtype],\n",
    "                               vectorize=True,\n",
    "                               dask='parallelized')\n",
    "    \n",
    "    return mo_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Let's create a feature image set with 3 time steps and containing 5 different Gaussian blobs to test the morphological operations. \n",
    "# Three of these blobs will be spatially offset at each time step, but will still overlap. Two other blobs will appear at time step 3. \n",
    "\n",
    "# Create blobs\n",
    "lon = np.arange(0, 360) + 0.5\n",
    "lat = np.arange(-90, 90) + 0.5\n",
    "x, y = np.meshgrid(lon, lat)\n",
    "\n",
    "x0 = 180; x1 = 225; x2 = 360; x3 = 1; x4 = 80\n",
    "y0 = 0; y1 = 20; y2 = -50; y4 = 40\n",
    "sigma0 = 15; sigma1 = 25; sigma2 = 30; sigma4 = 10\n",
    "\n",
    "blob0 = np.exp(-((x - x0)**2 + (y - y0)**2)/(2*sigma0**2))\n",
    "blob1 = np.exp(-((x - x1)**2 + (y - y1)**2)/(2*sigma1**2))\n",
    "blob2 = np.exp(-((x - x2)**2 + (y - y2)**2)/(2*sigma2**2))\n",
    "blob3 = np.exp(-((x - x4)**2 + (y - y4)**2)/(2*sigma4**2))\n",
    "blob4 = np.exp(-((x - x3)**2 + (y - y2)**2)/(2*sigma2**2))\n",
    "blob5 = np.exp(-((x - x2)**2 + (y - y4)**2)/(2*sigma0**2))\n",
    "blob6 = np.exp(-((x - x3)**2 + (y - y4)**2)/(2*sigma4**2))\n",
    "\n",
    "first_image = blob0+blob1+blob3-.5\n",
    "da = xr.DataArray(first_image[np.newaxis,:,:], dims=['time','lat', 'lon'],\n",
    "                  coords={'time':[1],'lat': lat, 'lon': lon})\n",
    "da_shift_01 = da.shift(lon=0, lat=-20, fill_value=-.5)\n",
    "da_shift_02 = da.shift(lon=0, lat=-40, fill_value=-.5)+(blob2+blob4+blob5+blob6)\n",
    "da_shift_03 = da.shift(lon=0, lat=-40, fill_value=-.5)+(blob2+blob5+blob6)\n",
    "\n",
    "\n",
    "da_3D = xr.concat((da,\n",
    "                   da_shift_01,\n",
    "                   da_shift_02,\n",
    "                   da_shift_03,), dim='time')\n",
    "da_3D['time'] = np.arange(1,5)\n",
    "\n",
    "mask = xr.DataArray(np.ones(da_3D[0,:,:].shape), coords=da_3D[0,:,:].coords)\n",
    "mask[60:90,120:190] = 0\n",
    "\n",
    "# ##### A useful plot:\n",
    "# da_3D[0,:,:].plot(vmin=-0.6, vmax=0.6, cmap='RdBu_r', extend='both')\n",
    "# c1 = da_3D[0,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles=':')\n",
    "# c2 = da_3D[1,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "# c3 = da_3D[2,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles='-')\n",
    "# plt.arrow(80,40,0,-38, head_width=8, head_length=6, lw=2, color='magenta', zorder=4)\n",
    "# plt.arrow(210,15,0,-38, head_width=8, head_length=6, lw=2, color='magenta', zorder=4)\n",
    "# h1,_ = c1.legend_elements(); h2,_ = c2.legend_elements(); h3,_ = c3.legend_elements()\n",
    "# plt.legend([h1[0], h2[0], h3[0]], ['t=0', 't=1', 't=2'])\n",
    "# plt.title('Feature Field at t=0 \\n Best Guess Objects Contoured at t=[0,1,2]', fontsize=14);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "################## TEST ##################\n",
    "\n",
    "# Now we will use Ocetrac to detect objects. \n",
    "# You can see, in this example, our best guess (shown previously) is pretty similar to Ocetrac (below)! \n",
    "# In the real world, these features are never perfectly Gaussian.\n",
    "\n",
    "# Find edges of blobs using morphological image processing.\n",
    "da_3D_dask = da_3D.chunk({'time': 1})\n",
    "mb = _morphological_operations(da_3D_dask, radius=8)\n",
    "assert isinstance(mb.data, dsa.Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Now we can assert that Ocetrac and our best guess estimates overlap by at least 80% and that the sum of the Ocetrac detected pixels equals 17411.\n",
    "ocetrac_blobs = da_3D.where(mb==True, drop=False, other=np.nan) \n",
    "best_guess_blobs = da_3D.where(da_3D>0, drop=False, other=np.nan) \n",
    "\n",
    "part = ocetrac_blobs.isin(best_guess_blobs)\n",
    "whole = best_guess_blobs.isin(best_guess_blobs)\n",
    "assert part.sum().values/whole.sum().values*100 >= 80\n",
    "assert part.sum().values == 26122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _id(binary_images):\n",
    "    '''label object from binary images, without trackin in time. '''\n",
    "    \n",
    "    unique_labels, num = xr.apply_ufunc(\n",
    "        label_np, \n",
    "        binary_images,\n",
    "        kwargs={'return_num': True, 'connectivity': 2},\n",
    "        input_core_dims=[['lat', 'lon', ]],\n",
    "        output_core_dims=[['lat', 'lon'], []],\n",
    "        output_dtypes=['i4', 'i4'],\n",
    "        dask='parallelized',\n",
    "        vectorize=True\n",
    "    )\n",
    "\n",
    "    #non_core_dims = set(binary_images.dims) - {'lat', 'lon'}\n",
    "    # TODO: stop assuming 3D images\n",
    "    \n",
    "    offset = num.cumsum().shift(time=1, fill_value=0)\n",
    "    unique_labels = xr.where(unique_labels > 0, unique_labels + offset, 0)\n",
    "    \n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Using the test data, let's label the objects we've identified. We should have 4 uniquely labeled blobs.\n",
    "ID = _id(mb)\n",
    "assert isinstance(ID.data, dsa.Array)\n",
    "ID.load()\n",
    "assert ID[2,:,:].max() == 10.\n",
    "assert all([i in ID[2,:,:] for i in range(5,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _filter_area(mo_binary, min_size_quartile):\n",
    "    '''calculatre area with regionprops'''\n",
    "    \n",
    "    unique_labels = _id(mo_binary)\n",
    "    props = regionprops(unique_labels.values.astype('int'))\n",
    "\n",
    "    labelprops = [p.label for p in props]\n",
    "    labelprops = xr.DataArray(labelprops, dims=['label'], coords={'label': labelprops}) \n",
    "    coords = [p.coords for p in props] # time, lat, lon\n",
    "    area = xr.DataArray([p.area for p in props], dims=['label'], coords={'label': labelprops})  # Number of pixels of the region.\n",
    "    min_area = np.percentile(area, min_size_quartile*100)\n",
    "\n",
    "#     area = []\n",
    "#     res = mo_binary.lat[1].values-mo_binary.lat[0].values # resolution of latitude\n",
    "#     for i in range(len(coords)):  \n",
    "#         area.append(np.sum((res*111)*np.cos(np.radians(mo_binary.lat[coords[i][:,0]].values)) * (res*111)))\n",
    "#     area = xr.DataArray(area, dims=['label'], coords={'label': labelprops})  \n",
    "#     min_area = np.percentile(area, min_size_quartile*100)\n",
    "    print('min area (km2) \\t', min_area)  \n",
    "    \n",
    "    keep_labels = labelprops.where(area>=min_area, drop=True)\n",
    "    ID_area = xr.DataArray(np.isin(unique_labels, keep_labels).reshape(unique_labels.shape),\n",
    "                               dims=unique_labels.dims, coords=unique_labels.coords)\n",
    "\n",
    "    return area, min_area, ID_area, labelprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area (km2) \t 3145.5\n",
      "percent of total area kept = 65.35\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "################## TEST [_filter_area] ##################\n",
    "\n",
    "# Given the blobs detected by Ocetrac, what is the minimum area defined by computing the 75th percentile of the blob area distribution.\n",
    "# Given this size criteria, only blob #2 is considered by Ocetrac.\n",
    "\n",
    "# id_wrap = id_3D_wrap.where(id_3D_wrap!= 0, drop=False, other=np.nan)\n",
    "min_size_quartile = .75\n",
    "\n",
    "area, min_area, ID_area, labelprops = _filter_area(mb, min_size_quartile)\n",
    "keep_labels = labelprops.where(area>=min_area, drop=True)\n",
    "assert (area.label[area>=min_area] == keep_labels).all()\n",
    "\n",
    "tot_area = int(np.sum(area.values))\n",
    "small_area = area.where(area<=min_area, drop=True)\n",
    "small_area = int(np.sum(small_area.values))\n",
    "percent_area_kept = 1-(small_area/tot_area)\n",
    "print('percent of total area kept = {}'.format(np.round(percent_area_kept*100,2)))\n",
    "# Is the percent area kept less than or equal to the minimum size quantile?\n",
    "assert percent_area_kept <= min_size_quartile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _label_either(data, **kwargs):\n",
    "    if isinstance(data, dsa.Array):\n",
    "        try:\n",
    "            from dask_image.ndmeasure import label as label_dask\n",
    "            def label_func(a, **kwargs):\n",
    "                ids, num = label_dask(a, **kwargs)\n",
    "                return ids\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Dask_image is required to use this function on Dask arrays. \"\n",
    "                \"Either install dask_image or else call .load() on your data.\"\n",
    "            )\n",
    "    else:\n",
    "        label_func = label_np\n",
    "    return label_func(data, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wrap(labels):\n",
    "    ''' Impose periodic boundary and wrap labels'''\n",
    "    first_column = labels[..., 0]\n",
    "    last_column = labels[..., -1]\n",
    "    \n",
    "    unique_first = np.unique(first_column[first_column>0])\n",
    "    \n",
    "    # This loop iterates over the unique values in the first column, finds the location of those values in \n",
    "    # the first columnm and then uses that index to replace the values in the last column with the first column value\n",
    "    for i in enumerate(unique_first):\n",
    "        new_ID = np.where(first_column == i[1])\n",
    "        bad_labels = np.unique(last_column[new_ID[0], new_ID[1]])\n",
    "        labels = np.where(labels == bad_labels, i[1], labels)\n",
    "\n",
    "    new_labels = np.unique(labels, return_inverse=True)[1].reshape(labels.shape)\n",
    "    \n",
    "    # recalculate the total number of labels \n",
    "    N = np.max(new_labels)\n",
    "\n",
    "    return new_labels, N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area (km2) \t 242.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "################## TEST [_filter_area] ##################\n",
    "radius=8\n",
    "min_size_quartile = 0\n",
    "binary_images = _morphological_operations(da_3D_dask, radius=radius) \n",
    "area, min_area, ID_area, labelprops = _filter_area(binary_images, min_size_quartile)\n",
    "ID_area_masked = ID_area.where(mask==1, drop=False, other=0)\n",
    "labels, num = _label_either(ID_area_masked, return_num= True, connectivity=3)\n",
    "new_labels, N = _wrap(labels)\n",
    "new_labels = xr.DataArray(new_labels, coords=da_3D_dask.coords)\n",
    "\n",
    "assert int(N)==4\n",
    "assert (new_labels.where(mask==0, drop=True)==0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def track(da, mask, radius=8, area_quantile=0.75):\n",
    "    '''Image labeling and tracking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xarray.DataArray\n",
    "        The data to label.\n",
    "    \n",
    "    radius : int\n",
    "        size of the structuring element used in morphological opening and closing.\n",
    "        \n",
    "    area_quantile : float\n",
    "        quantile used to define the threshold of the smallest area object retained in tracking.\n",
    "        \n",
    "    mask : xarray.DataArray\n",
    "        The mask of ponts to ignore. Must be binary.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    labels : xarray.DataArray\n",
    "        Integer labels of the connected regions.\n",
    "    '''\n",
    "        \n",
    "    # Converts data to binary, defines structuring element, and performs morphological closing then opening\n",
    "    binary_images = _morphological_operations(da, radius=radius) \n",
    "    \n",
    "    area, min_area, ID_area, labelprops = _filter_area(binary_images, area_quantile)\n",
    "\n",
    "#     if mask.any():\n",
    "#         try:\n",
    "#             ID_area = ID_area.where(mask==1, drop=False, other=0)\n",
    "#             labels, num = _label_either(ID_area, return_num= True, connectivity=3)\n",
    "#         except ImportError:\n",
    "#             raise ImportError(\n",
    "#                 \"Mask not used.  \"\n",
    "#                 \"Check that dimensions equal da and that it contains a binary set.\"\n",
    "#             )\n",
    "#     else:\n",
    "#         labels, num = _label_either(ID_area, return_num= True, connectivity=3)\n",
    "    \n",
    "    # Apply mask\n",
    "#     ID_area = ID_area.where(mask==1, drop=False, other=0)\n",
    "    \n",
    "    labels, num = _label_either(ID_area, return_num= True, connectivity=3)\n",
    "        \n",
    "    new_labels, N = _wrap(labels)\n",
    "    new_labels = xr.DataArray(new_labels, coords=da.coords)\n",
    "\n",
    "\n",
    "    # Calculate Percent of total MHW area retained\n",
    "    tot_area = int(np.sum(area.values))\n",
    "    small_area = area.where(area<=min_area, drop=True)\n",
    "    small_area = int(np.sum(small_area.values))\n",
    "    percent_area_kept = 1-(small_area/tot_area)\n",
    "\n",
    "    new_labels = new_labels.rename('labels')\n",
    "    new_labels.attrs['min_area'] = min_area\n",
    "    new_labels.attrs['percent_area_kept'] = percent_area_kept\n",
    "    print('inital features identified \\t', int(new_labels.max().values))\n",
    "    \n",
    "\n",
    "    print('final features tracked \\t', int(N))\n",
    "    \n",
    "    return new_labels, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "# this is the same as running nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ocetrac-2020]",
   "language": "python",
   "name": "conda-env-miniconda3-ocetrac-2020-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
