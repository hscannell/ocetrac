{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocetrac\n",
    "\n",
    "> Track and label marine heatwaves from geospatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nbdev.showdoc import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from skimage.measure import label, regionprops \n",
    "# import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _morphological_operations(da, radius=8): \n",
    "    '''Converts xarray.DataArray to binary, defines structuring element, and performs morphological closing then opening.\n",
    "    Parameters\n",
    "    ----------\n",
    "    da     : xarray.DataArray\n",
    "            The data to label\n",
    "    radius : int\n",
    "            Length of grid spacing to define the radius of the structing element used in morphological closing and opening.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Convert images to binary. All positive values == 1, otherwise == 0\n",
    "    bitmap_binary = da.where(da>0, drop=False, other=0)\n",
    "    bitmap_binary = bitmap_binary.where(bitmap_binary==0, drop=False, other=1)\n",
    "    \n",
    "    # Define structuring element\n",
    "    diameter = radius*2\n",
    "    x = np.arange(-radius, radius+1)\n",
    "    x, y = np.meshgrid(x, x)\n",
    "    r = x**2+y**2 \n",
    "    se = r<radius**2\n",
    "\n",
    "    def binary_open_close(bitmap_binary):\n",
    "        bitmap_binary_padded = np.pad(bitmap_binary,\n",
    "                                      ((diameter, diameter), (diameter, diameter)),\n",
    "                                      mode='reflect')\n",
    "        s1 = scipy.ndimage.binary_closing(bitmap_binary_padded, se, iterations=1)\n",
    "        s2 = scipy.ndimage.binary_opening(s1, se, iterations=1)\n",
    "        unpadded= s2[diameter:-diameter, diameter:-diameter]\n",
    "        return unpadded\n",
    "    \n",
    "    mo_binary = xr.apply_ufunc(binary_open_close, bitmap_binary,\n",
    "                               input_core_dims=[['lat', 'lon']],\n",
    "                               output_core_dims=[['lat', 'lon']],\n",
    "                               output_dtypes=[bitmap_binary.dtype],\n",
    "                               vectorize=True,\n",
    "                               dask='parallelized')\n",
    "    \n",
    "    return mo_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Let's create a feature image set with 3 time steps and containing 5 different Gaussian blobs to test the morphological operations. \n",
    "# Three of these blobs will be spatially offset at each time step, but will still overlap. Two other blobs will appear at time step 3. \n",
    "\n",
    "# Create blobs\n",
    "lon = np.arange(0, 360) + 0.5\n",
    "lat = np.arange(-90, 90) + 0.5\n",
    "x, y = np.meshgrid(lon, lat)\n",
    "\n",
    "x0 = 180; x1 = 225; x2 = 360; x3 = 1; x4 = 80\n",
    "y0 = 0; y1 = 20; y2 = -50; y4 = 40\n",
    "sigma0 = 15; sigma1 = 25; sigma2 = 30; sigma4 = 10\n",
    "\n",
    "blob0 = np.exp(-((x - x0)**2 + (y - y0)**2)/(2*sigma0**2))\n",
    "blob1 = np.exp(-((x - x1)**2 + (y - y1)**2)/(2*sigma1**2))\n",
    "blob2 = np.exp(-((x - x2)**2 + (y - y2)**2)/(2*sigma2**2))\n",
    "blob3 = np.exp(-((x - x4)**2 + (y - y4)**2)/(2*sigma4**2))\n",
    "blob4 = np.exp(-((x - x3)**2 + (y - y2)**2)/(2*sigma2**2))\n",
    "\n",
    "da = xr.DataArray((blob0+blob1+blob3)-.5, dims=['lat', 'lon'],\n",
    "                  coords={'lat': lat, 'lon': lon})\n",
    "da_shift_01 = da.shift(lon=0, lat=-20, fill_value=-.5)\n",
    "da_shift_02 = da.shift(lon=0, lat=-40, fill_value=-.5)+(blob2+blob4)\n",
    "da_3D = xr.concat((da.expand_dims(dim='time'),\n",
    "                   da_shift_01.expand_dims(dim='time'),\n",
    "                   da_shift_02.expand_dims(dim='time')), dim='time')\n",
    "\n",
    "\n",
    "# ##### A useful plot:\n",
    "# da_3D[0,:,:].plot(vmin=-0.6, vmax=0.6, cmap='RdBu_r', extend='both')\n",
    "# c1 = da_3D[0,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles=':')\n",
    "# c2 = da_3D[1,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "# c3 = da_3D[2,:,:].plot.contour(levels=[0], colors='k', linewidths=2, linestyles='-')\n",
    "# plt.arrow(80,40,0,-38, head_width=8, head_length=6, lw=2, color='magenta', zorder=4)\n",
    "# plt.arrow(210,15,0,-38, head_width=8, head_length=6, lw=2, color='magenta', zorder=4)\n",
    "# h1,_ = c1.legend_elements(); h2,_ = c2.legend_elements(); h3,_ = c3.legend_elements()\n",
    "# plt.legend([h1[0], h2[0], h3[0]], ['t=0', 't=1', 't=2'])\n",
    "# plt.title('Feature Field at t=0 \\n Best Guess Objects Contoured at t=[0,1,2]', fontsize=14);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "################## TEST ##################\n",
    "\n",
    "# Now we will use Ocetrac to detect objects. \n",
    "# You can see, in this example, our best guess (shown previously) is pretty similar to Ocetrac (below)! \n",
    "# In the real world, these features are never perfectly Gaussian.\n",
    "\n",
    "# Find edges of blobs using morphological image processing.\n",
    "da_3D_dask = da_3D.chunk({'time': 1})\n",
    "mo_binary = _morphological_operations(da_3D_dask, radius=8)\n",
    "import dask.array as dsa\n",
    "assert isinstance(mo_binary.data, dsa.Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Now we can assert that Ocetrac and our best guess estimates overlap by at least 80% and that the sum of the Ocetrac detected pixels equals 17411.\n",
    "ocetrac_blobs = da_3D.where(mo_binary==True, drop=False, other=np.nan) \n",
    "best_guess_blobs = da_3D.where(da_3D>0, drop=False, other=np.nan) \n",
    "\n",
    "part = ocetrac_blobs.isin(best_guess_blobs)\n",
    "whole = best_guess_blobs.isin(best_guess_blobs)\n",
    "assert part.sum()/whole.sum()*100 >= 80\n",
    "assert part.sum() == 18050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from skimage.measure import label as label_np\n",
    "\n",
    "def _label_either(data, **kwargs):\n",
    "    if isinstance(data, dsa.Array):\n",
    "        try:\n",
    "            from dask_image.ndmeasure import label as label_dask\n",
    "            def label_func(a, **kwargs):\n",
    "                ids, num = label_dask(a, **kwargs)\n",
    "                return ids\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Dask_image is required to use this function on Dask arrays. \"\n",
    "                \"Either install dask_image or else call .load() on your data.\"\n",
    "            )\n",
    "    else:\n",
    "        label_func = label_np\n",
    "    return label_func(data, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _id(binary_images):\n",
    "    '''label features from binary images'''\n",
    "    \n",
    "    labels, num = xr.apply_ufunc(\n",
    "        label, \n",
    "        binary_images,\n",
    "        kwargs={'return_num': True, 'connectivity': 2},\n",
    "        input_core_dims=[['lat', 'lon', ]],\n",
    "        output_core_dims=[['lat', 'lon'], []],\n",
    "        output_dtypes=['i4', 'i4'],\n",
    "        dask='parallelized',\n",
    "        vectorize=True\n",
    "    )\n",
    "\n",
    "    #non_core_dims = set(binary_images.dims) - {'lat', 'lon'}\n",
    "    # TODO: stop assuming 3D images\n",
    "    offset = num.cumsum().shift(time=1, fill_value=0)\n",
    "    unique_labels = xr.where(labels > 0, labels + offset, 0)\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Using the test data, let's label the objects we've identified. We should have 4 uniquely labeled blobs.\n",
    "ID = _id(mo_binary)\n",
    "assert isinstance(ID.data, dsa.Array)\n",
    "ID.load()\n",
    "assert ID[2,:,:].max() == 8.\n",
    "assert all([i in ID[2,:,:] for i in range(5,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wrap_labels(labels):\n",
    "    '''wrap labels that cross prime meridian '''\n",
    "\n",
    "    prime = labels.loc[dict(lon=labels.lon[:2])]\n",
    "\n",
    "    prime_ids = np.unique(prime)[(~np.isnan(np.unique(prime)))&(np.unique(prime)>0)].astype('float')\n",
    "    mirrormapBool = xr.DataArray(np.in1d(labels, prime_ids).reshape(labels.shape),\n",
    "                                 dims=labels.dims,\n",
    "                                 coords=labels.coords)\n",
    "    earth2 = labels.where(mirrormapBool==True, drop=False, other=0)\n",
    "    earth1 = labels.where(mirrormapBool==False, drop=False, other=0) # Remove label from origonal map\n",
    " \n",
    "    # Concatenate and convert to binary\n",
    "    res = labels.lon[1].values-labels.lon[0].values # resolution of longitude\n",
    "    two_earths = xr.concat([earth1, earth2], dim='lon')\n",
    "    two_earths['lon'] = np.arange(float(two_earths.lon[0].values),(two_earths.lon[-1].values*2)+res,res)\n",
    "    bitmap_binary_2E = two_earths.where(two_earths>0, drop=False, other=0)\n",
    "    bitmap_binary_2E = bitmap_binary_2E.where(bitmap_binary_2E==0, drop=False, other=1)\n",
    "    bitmap_bool_2E = bitmap_binary_2E>0\n",
    "    \n",
    "    return bitmap_binary_2E, bitmap_bool_2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "################## TEST ##################\n",
    "\n",
    "# In our test image, there is a blob that is split across the prime meridian. \n",
    "# Ocetrac should be able to identify that these features belong together. \n",
    "bitmap_binary_2E, bitmap_bool_2E = _wrap_labels(ID)\n",
    "\n",
    "# # # Let's relabel the wrapped blobs\n",
    "ID_wrap = _id(bitmap_bool_2E)\n",
    "\n",
    "# # # Ocetrac should only identify 3 events now at time 2.\n",
    "assert ID_wrap[2,:,:].max() == 7.\n",
    "assert all([i in ID_wrap[2,:,:] for i in range(5,8)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _id_area(labels, min_size_quartile):\n",
    "    '''calculatre area with regionprops'''\n",
    "    \n",
    "    props = regionprops(labels.values.astype('int'))\n",
    "\n",
    "    labelprops = [p.label for p in props]\n",
    "    labelprops = xr.DataArray(labelprops, dims=['label'], coords={'label': labelprops}) \n",
    "    coords = [p.coords for p in props] # time, lat, lon\n",
    "\n",
    "    area = []\n",
    "    res = labels.lat[1].values-labels.lat[0].values # resolution of latitude\n",
    "    for i in range(len(coords)):  \n",
    "        area.append(np.sum((res*111)*np.cos(np.radians(labels.lat[coords[i][:,0]].values)) * (res*111)))\n",
    "    area = xr.DataArray(area, dims=['label'], coords={'label': labelprops})  \n",
    "    min_area = np.percentile(area, min_size_quartile*100)\n",
    "    print('min area (km2) \\t', min_area)  \n",
    "    \n",
    "    return area, min_area, labelprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area (km2) \t 1787969.2516381098\n",
      "percent of total area kept = 66.66\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "################## TEST ##################\n",
    "\n",
    "# Given the blobs detected by Ocetrac, what is the minimum area defined by computing the 75th percentile of the blob area distribution.\n",
    "# Given this size criteria, only blob #2 is considered by Ocetrac.\n",
    "\n",
    "# id_wrap = id_3D_wrap.where(id_3D_wrap!= 0, drop=False, other=np.nan)\n",
    "min_size_quartile = .75\n",
    "\n",
    "area, min_area, labelprops = _id_area(ID_wrap, min_size_quartile)\n",
    "keep_labels = labelprops.where(area>=min_area, drop=True)\n",
    "assert (area.label[area>=min_area] == keep_labels).all()\n",
    "\n",
    "tot_area = int(np.sum(area.values))\n",
    "small_area = area.where(area<=min_area, drop=True)\n",
    "small_area = int(np.sum(small_area.values))\n",
    "percent_area_kept = 1-(small_area/tot_area)\n",
    "print('percent of total area kept = {}'.format(np.round(percent_area_kept*100,2)))\n",
    "# Is the percent area kept less than or equal to the minimum size quantile?\n",
    "assert percent_area_kept <= min_size_quartile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def track(da, radius=8, area_quantile=0.75):\n",
    "    '''Image labeling and tracking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xarray.DataArray\n",
    "        The data to label.\n",
    "    \n",
    "    radius : int\n",
    "        size of the structuring element used in morphological opening and closing.\n",
    "        \n",
    "    area_quantile : float\n",
    "        quantile used to define the threshold of the smallest area object retained in tracking.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    labels : xarray.DataArray\n",
    "        Integer labels of the connected regions.\n",
    "    '''\n",
    "        \n",
    "    # Converts data to binary, defines structuring element, and performs morphological closing then opening\n",
    "    binary_images = _morphological_operations(da, radius=radius) \n",
    "    \n",
    "    # label features from binary images\n",
    "    ID = _id(binary_images)\n",
    "\n",
    "    # wrap labels that cross prime meridian\n",
    "    bitmap_binary_2E, bitmap_bool_2E = _wrap_labels(ID)\n",
    "    \n",
    "    ### ! Reapply land maks HERE\n",
    "    \n",
    "    # relabel 2D features from binary images that are wrapped around meridian\n",
    "    ID_wrap = _id(bitmap_binary_2E)\n",
    "\n",
    "    # calculatre area with regionprops\n",
    "    area, min_area, labelprops = _id_area(ID_wrap, area_quantile)\n",
    "    \n",
    "    keep_labels = labelprops.where(area>=min_area, drop=True)\n",
    "\n",
    "    ID_area_bool = xr.DataArray(np.isin(ID_wrap, keep_labels).reshape(ID_wrap.shape),\n",
    "                               dims=ID_wrap.dims, coords=ID_wrap.coords)\n",
    "\n",
    "    # Calculate Percent of total MHW area retained\n",
    "    tot_area = int(np.sum(area.values))\n",
    "    small_area = area.where(area<=min_area, drop=True)\n",
    "    small_area = int(np.sum(small_area.values))\n",
    "    percent_area_kept = 1-(small_area/tot_area)\n",
    "\n",
    "    features = _id(ID_area_bool)\n",
    "    features = features.rename('labels')\n",
    "    features.attrs['min_area'] = min_area\n",
    "    features.attrs['percent_area_kept'] = percent_area_kept\n",
    "    print('inital features identified \\t', int(features.max().values))\n",
    "    \n",
    "    ## Track labeled features\n",
    "    bitmap_binary = features.where(features>0, drop=False, other=0)\n",
    "    bitmap_binary = bitmap_binary.where(bitmap_binary==0, drop=False, other=1)\n",
    "    \n",
    "    ####### Label with Skimage\n",
    "    # relabel\n",
    "    label_sk3, final_features = label(bitmap_binary, connectivity=3, return_num=True)\n",
    "    # explore scikit-image dask image\n",
    "    \n",
    "    label_sk3 = xr.DataArray(label_sk3, dims=['time','lat','lon'],\n",
    "                          coords={'time': bitmap_binary.time, 'lat': bitmap_binary.lat,'lon': bitmap_binary.lon})\n",
    "    binary_labels = label_sk3.where(label_sk3>0, drop=False, other=0)\n",
    "    split_lon = int(binary_labels.shape[2]/2)\n",
    "    origonal_map = binary_labels[:,:,split_lon:].values + binary_labels[:,:,:split_lon].values\n",
    "    # Convert labels to DataArray\n",
    "\n",
    "    labels = xr.DataArray(origonal_map, dims=['time','lat','lon'],\n",
    "                          coords={'time': binary_images.time, 'lat': binary_images.lat,'lon': binary_images.lon})\n",
    "    labels = labels.where(labels > 0, drop=False, other=np.nan)\n",
    "    \n",
    "\n",
    "    print('final features tracked \\t', final_features)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "# this is the same as running nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ocetrac-2020]",
   "language": "python",
   "name": "conda-env-miniconda3-ocetrac-2020-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
